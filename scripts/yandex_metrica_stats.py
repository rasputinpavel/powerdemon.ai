#!/usr/bin/env python3
"""
Yandex.Metrica Stats Collector for PowerDemon.AI
–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –Ω–∞ —Å–∞–π—Ç–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ reports/.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python3 scripts/yandex_metrica_stats.py --business netashi
  python3 scripts/yandex_metrica_stats.py --business netashi --days 7

Credentials: businesses/{name}/.credentials
  YANDEX_METRICA_COUNTER=12345678
  YANDEX_DIRECT_TOKEN=...  (—Ç–æ—Ç –∂–µ OAuth-—Ç–æ–∫–µ–Ω)
"""

import sys
import csv
import argparse
import requests
from pathlib import Path
from datetime import datetime, timedelta

BUSINESSES_DIR = Path(__file__).parent.parent / "businesses"
METRICA_API = "https://api-metrika.yandex.net/stat/v1/data"


def load_credentials(business: str) -> dict:
    cred_file = BUSINESSES_DIR / business / ".credentials"
    env = {}
    if cred_file.exists():
        for line in cred_file.read_text().splitlines():
            if "=" in line and not line.startswith("#"):
                k, v = line.split("=", 1)
                env[k.strip()] = v.strip()
    return env


def get_metrica_data(token: str, counter_id: str, date_from: str, date_to: str,
                     metrics: str, dimensions: str = "ym:s:date", group: str = "day"):
    """–ó–∞–ø—Ä–æ—Å –∫ API –Ø–Ω–¥–µ–∫—Å.–ú–µ—Ç—Ä–∏–∫–∏"""
    headers = {"Authorization": f"OAuth {token}"}
    params = {
        "ids": counter_id,
        "date1": date_from,
        "date2": date_to,
        "metrics": metrics,
        "dimensions": dimensions,
        "group": group,
        "limit": 100,
    }
    response = requests.get(METRICA_API, headers=headers, params=params)
    if response.status_code != 200:
        raise Exception(f"Metrica API Error {response.status_code}: {response.text}")
    return response.json()


def get_traffic_summary(token: str, counter_id: str, date_from: str, date_to: str) -> list:
    """–¢—Ä–∞—Ñ–∏–∫ –ø–æ –¥–Ω—è–º: –≤–∏–∑–∏—Ç—ã, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏, –ø—Ä–æ—Å–º–æ—Ç—Ä—ã, –æ—Ç–∫–∞–∑—ã, –≤—Ä–µ–º—è"""
    metrics = "ym:s:visits,ym:s:users,ym:s:pageviews,ym:s:bounceRate,ym:s:avgVisitDurationSeconds"
    data = get_metrica_data(token, counter_id, date_from, date_to, metrics)

    rows = []
    for item in data.get("data", []):
        date = item["dimensions"][0]["name"]
        m = item["metrics"]
        rows.append({
            "date": date,
            "visits": int(m[0]),
            "users": int(m[1]),
            "pageviews": int(m[2]),
            "bounce_rate": round(m[3], 1),
            "avg_duration": round(m[4], 0),
        })
    return rows


def get_traffic_sources(token: str, counter_id: str, date_from: str, date_to: str) -> list:
    """–ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Ç—Ä–∞—Ñ–∏–∫–∞"""
    metrics = "ym:s:visits,ym:s:users,ym:s:bounceRate"
    dimensions = "ym:s:lastTrafficSource"
    data = get_metrica_data(token, counter_id, date_from, date_to, metrics, dimensions)

    rows = []
    for item in data.get("data", []):
        source = item["dimensions"][0]["name"]
        m = item["metrics"]
        rows.append({
            "source": source,
            "visits": int(m[0]),
            "users": int(m[1]),
            "bounce_rate": round(m[2], 1),
        })
    return rows


def get_search_queries(token: str, counter_id: str, date_from: str, date_to: str) -> list:
    """–ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã (–ø–æ –∫–∞–∫–∏–º –∑–∞–ø—Ä–æ—Å–∞–º –ø—Ä–∏—Ö–æ–¥—è—Ç)"""
    metrics = "ym:s:visits"
    dimensions = "ym:s:lastSearchPhrase"
    data = get_metrica_data(token, counter_id, date_from, date_to, metrics, dimensions)

    rows = []
    for item in data.get("data", []):
        query = item["dimensions"][0]["name"]
        if query and query != "(not set)":
            rows.append({
                "query": query,
                "visits": int(item["metrics"][0]),
            })
    return sorted(rows, key=lambda x: x["visits"], reverse=True)


def generate_report_md(traffic: list, sources: list, queries: list,
                       date_from: str, date_to: str, business: str) -> str:
    """–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å MD-–æ—Ç—á—ë—Ç –ø–æ –ú–µ—Ç—Ä–∏–∫–µ"""
    report = f"# –û—Ç—á—ë—Ç –Ø–Ω–¥–µ–∫—Å.–ú–µ—Ç—Ä–∏–∫–∞: {business}\n"
    report += f"**–ü–µ—Ä–∏–æ–¥:** {date_from} ‚Äî {date_to}\n"
    report += f"**–î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"

    if not traffic:
        report += "> –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\n"
        return report

    # –°–≤–æ–¥–∫–∞
    total_visits = sum(r["visits"] for r in traffic)
    total_users = sum(r["users"] for r in traffic)
    total_views = sum(r["pageviews"] for r in traffic)
    avg_bounce = sum(r["bounce_rate"] for r in traffic) / len(traffic) if traffic else 0
    avg_duration = sum(r["avg_duration"] for r in traffic) / len(traffic) if traffic else 0

    report += "## –°–≤–æ–¥–∫–∞\n\n"
    report += "| –í–∏–∑–∏—Ç—ã | –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ | –ü—Ä–æ—Å–º–æ—Ç—Ä—ã | –û—Ç–∫–∞–∑—ã | –°—Ä. –≤—Ä–µ–º—è |\n"
    report += "|--------|-------------|-----------|--------|----------|\n"
    bounce_flag = "‚ö†Ô∏è" if avg_bounce > 50 else "‚úÖ"
    report += f"| {total_visits} | {total_users} | {total_views} | {avg_bounce:.0f}% {bounce_flag} | {avg_duration:.0f} —Å–µ–∫ |\n\n"

    # –ü–æ –¥–Ω—è–º
    report += "## –ü–æ –¥–Ω—è–º\n\n"
    report += "| –î–∞—Ç–∞ | –í–∏–∑–∏—Ç—ã | –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ | –ü—Ä–æ—Å–º–æ—Ç—Ä—ã | –û—Ç–∫–∞–∑—ã |\n"
    report += "|------|--------|-------------|-----------|--------|\n"
    for r in traffic:
        report += f"| {r['date']} | {r['visits']} | {r['users']} | {r['pageviews']} | {r['bounce_rate']}% |\n"

    # –ò—Å—Ç–æ—á–Ω–∏–∫–∏
    if sources:
        report += "\n## –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Ç—Ä–∞—Ñ–∏–∫–∞\n\n"
        report += "| –ò—Å—Ç–æ—á–Ω–∏–∫ | –í–∏–∑–∏—Ç—ã | –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ | –û—Ç–∫–∞–∑—ã |\n"
        report += "|----------|--------|-------------|--------|\n"
        for r in sorted(sources, key=lambda x: x["visits"], reverse=True):
            report += f"| {r['source']} | {r['visits']} | {r['users']} | {r['bounce_rate']}% |\n"

    # –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    if queries:
        report += "\n## –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã (—Ç–æ–ø)\n\n"
        report += "| –ó–∞–ø—Ä–æ—Å | –í–∏–∑–∏—Ç—ã |\n"
        report += "|--------|--------|\n"
        for r in queries[:20]:
            report += f"| {r['query']} | {r['visits']} |\n"

    report += "\n---\n*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫—Ä–∏–ø—Ç–æ–º yandex_metrica_stats.py*\n"
    return report


def append_to_csv(traffic: list, csv_path: Path):
    """–î–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π CSV"""
    file_exists = csv_path.exists()
    fieldnames = ["–î–∞—Ç–∞", "–í–∏–∑–∏—Ç—ã", "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏", "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", "–û—Ç–∫–∞–∑—ã %", "–°—Ä. –≤—Ä–µ–º—è (—Å–µ–∫)"]

    existing_dates = set()
    if file_exists:
        with open(csv_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter=";")
            for row in reader:
                existing_dates.add(row.get("–î–∞—Ç–∞", ""))

    new_rows = []
    for r in traffic:
        if r["date"] not in existing_dates:
            new_rows.append({
                "–î–∞—Ç–∞": r["date"],
                "–í–∏–∑–∏—Ç—ã": r["visits"],
                "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏": r["users"],
                "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": r["pageviews"],
                "–û—Ç–∫–∞–∑—ã %": r["bounce_rate"],
                "–°—Ä. –≤—Ä–µ–º—è (—Å–µ–∫)": r["avg_duration"],
            })

    if not new_rows:
        print("   CSV: –Ω–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        return

    with open(csv_path, "a", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=";")
        if not file_exists:
            writer.writeheader()
        writer.writerows(new_rows)
    print(f"   CSV: +{len(new_rows)} —Å—Ç—Ä–æ–∫ ‚Üí {csv_path.name}")


def main():
    parser = argparse.ArgumentParser(description="–°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ø–Ω–¥–µ–∫—Å.–ú–µ—Ç—Ä–∏–∫–∏")
    parser.add_argument("--business", required=True)
    parser.add_argument("--days", type=int, default=1, help="–ó–∞ —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)")
    args = parser.parse_args()

    creds = load_credentials(args.business)
    token = creds.get("YANDEX_DIRECT_TOKEN")  # –¢–æ—Ç –∂–µ OAuth-—Ç–æ–∫–µ–Ω
    counter_id = creds.get("YANDEX_METRICA_COUNTER")

    if not token:
        print(f"‚ùå –ù–µ—Ç YANDEX_DIRECT_TOKEN –≤ businesses/{args.business}/.credentials")
        sys.exit(1)
    if not counter_id:
        print(f"‚ùå –ù–µ—Ç YANDEX_METRICA_COUNTER –≤ businesses/{args.business}/.credentials")
        print(f"   –î–æ–±–∞–≤—å: YANDEX_METRICA_COUNTER=12345678")
        print(f"   ID —Å—á—ë—Ç—á–∏–∫–∞ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –Ω–∞ metrika.yandex.ru")
        sys.exit(1)

    date_to = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    date_from = (datetime.now() - timedelta(days=args.days)).strftime("%Y-%m-%d")

    print(f"üìä –ú–µ—Ç—Ä–∏–∫–∞ {args.business} –∑–∞ {date_from} ‚Äî {date_to}...")

    try:
        traffic = get_traffic_summary(token, counter_id, date_from, date_to)
        sources = get_traffic_sources(token, counter_id, date_from, date_to)
        queries = get_search_queries(token, counter_id, date_from, date_to)
        print(f"   –î–Ω–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏: {len(traffic)}")

        # –ü–∞–ø–∫–∞ –æ—Ç—á—ë—Ç–æ–≤ (–æ–±—â–∞—è –¥–ª—è —Å–∞–π—Ç–∞, –Ω–µ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞)
        reports_dir = BUSINESSES_DIR / args.business / "projects" / "yandex-direct" / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)

        # MD-–æ—Ç—á—ë—Ç
        report_md = generate_report_md(traffic, sources, queries, date_from, date_to, args.business)
        md_path = reports_dir / f"metrica_{date_from}.md"
        md_path.write_text(report_md)
        print(f"‚úÖ MD-–æ—Ç—á—ë—Ç: {md_path.name}")

        # –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π CSV
        csv_path = reports_dir / "metrica.csv"
        append_to_csv(traffic, csv_path)
        print(f"‚úÖ CSV: metrica.csv")

        print("\n" + report_md)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
